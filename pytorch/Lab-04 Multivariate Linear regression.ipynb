{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab-04-1 Multivariate Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[73, 80, 75], \n",
    "                             [93, 88, 93], \n",
    "                             [89, 91, 90], \n",
    "                             [96, 98, 100], \n",
    "                             [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model without torch.nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.6190, -0.4464, -0.5915], requires_grad=True),\n",
       " tensor([1.1979], requires_grad=True))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = torch.randn(x_train.size(1), requires_grad=True)\n",
    "b = torch.randn(1, requires_grad=True)\n",
    "W, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD([W, b], lr=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-33.6915, -35.5298, -37.5706, -42.2776, -24.4840],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.matmul(W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 y_pred: tensor([-33.6915, -35.5298, -37.5706, -42.2776, -24.4840]) Cost: 42988.960938\n",
      "W: [ 0.97282803 -0.09282294 -0.23350555] b: 1.20\n",
      "Epoch    1/20 y_pred: tensor([47.2797, 61.7906, 58.3213, 62.1463, 49.7467]) Cost: 13476.015625\n",
      "W: [ 1.1708956   0.10517381 -0.03307883] b: 1.20\n",
      "Epoch    2/20 y_pred: tensor([ 92.6127, 116.2766, 112.0077, 120.6094,  91.3056]) Cost: 4225.273438\n",
      "W: [1.2817597  0.216054   0.07913034] b: 1.21\n",
      "Epoch    3/20 y_pred: tensor([117.9932, 146.7811, 142.0649, 153.3409, 114.5727]) Cost: 1325.655518\n",
      "W: [1.343802   0.2781608  0.14194974] b: 1.21\n",
      "Epoch    4/20 y_pred: tensor([132.2029, 163.8594, 158.8928, 171.6660, 127.5990]) Cost: 416.778900\n",
      "W: [1.3785105  0.31296116 0.17711765] b: 1.21\n",
      "Epoch    5/20 y_pred: tensor([140.1587, 173.4207, 168.3142, 181.9257, 134.8917]) Cost: 131.893616\n",
      "W: [1.397916   0.33247364 0.19680446] b: 1.21\n",
      "Epoch    6/20 y_pred: tensor([144.6130, 178.7736, 173.5890, 187.6697, 138.9744]) Cost: 42.596901\n",
      "W: [1.4087538  0.343427   0.20782402] b: 1.21\n",
      "Epoch    7/20 y_pred: tensor([147.1071, 181.7704, 176.5422, 190.8857, 141.2600]) Cost: 14.606293\n",
      "W: [1.4147949  0.3495884  0.21399106] b: 1.21\n",
      "Epoch    8/20 y_pred: tensor([148.5036, 183.4480, 178.1956, 192.6862, 142.5394]) Cost: 5.832298\n",
      "W: [1.4181505  0.35306695 0.2174414 ] b: 1.21\n",
      "Epoch    9/20 y_pred: tensor([149.2856, 184.3871, 179.1214, 193.6943, 143.2555]) Cost: 3.081545\n",
      "W: [1.4200027  0.35504347 0.21937072] b: 1.21\n",
      "Epoch   10/20 y_pred: tensor([149.7237, 184.9128, 179.6398, 194.2588, 143.6562]) Cost: 2.218781\n",
      "W: [1.4210131  0.35617906 0.22044851] b: 1.21\n",
      "Epoch   11/20 y_pred: tensor([149.9691, 185.2069, 179.9300, 194.5749, 143.8804]) Cost: 1.947806\n",
      "W: [1.4215523  0.3568438  0.22104953] b: 1.21\n",
      "Epoch   12/20 y_pred: tensor([150.1068, 185.3714, 180.0926, 194.7519, 144.0057]) Cost: 1.862308\n",
      "W: [1.4218276  0.35724494 0.22138365] b: 1.21\n",
      "Epoch   13/20 y_pred: tensor([150.1840, 185.4634, 180.1837, 194.8510, 144.0756]) Cost: 1.834953\n",
      "W: [1.4219551  0.3574985  0.22156833] b: 1.21\n",
      "Epoch   14/20 y_pred: tensor([150.2274, 185.5148, 180.2347, 194.9066, 144.1146]) Cost: 1.825840\n",
      "W: [1.422      0.35766944 0.22166938] b: 1.21\n",
      "Epoch   15/20 y_pred: tensor([150.2520, 185.5434, 180.2634, 194.9378, 144.1363]) Cost: 1.822443\n",
      "W: [1.4219987  0.3577941  0.22172357] b: 1.21\n",
      "Epoch   16/20 y_pred: tensor([150.2659, 185.5593, 180.2795, 194.9553, 144.1482]) Cost: 1.820802\n",
      "W: [1.4219714  0.3578928  0.22175153] b: 1.21\n",
      "Epoch   17/20 y_pred: tensor([150.2739, 185.5680, 180.2886, 194.9651, 144.1547]) Cost: 1.819765\n",
      "W: [1.4219296 0.357977  0.2217648] b: 1.21\n",
      "Epoch   18/20 y_pred: tensor([150.2786, 185.5728, 180.2937, 194.9707, 144.1581]) Cost: 1.818870\n",
      "W: [1.4218798  0.3580531  0.22176988] b: 1.21\n",
      "Epoch   19/20 y_pred: tensor([150.2814, 185.5753, 180.2966, 194.9739, 144.1598]) Cost: 1.818068\n",
      "W: [1.4218253  0.3581246  0.22177036] b: 1.21\n",
      "Epoch   20/20 y_pred: tensor([150.2832, 185.5766, 180.2983, 194.9757, 144.1606]) Cost: 1.817254\n",
      "W: [1.4217683  0.35819358 0.22176827] b: 1.21\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "for epoch in range(n_epochs + 1):\n",
    "    \n",
    "    output = (x_train.matmul(W) + b).unsqueeze(1)\n",
    "    \n",
    "    loss = torch.mean((output - y_train)**2)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    print('Epoch {:4d}/{} y_pred: {} Cost: {:.6f}'.format(\n",
    "        epoch, n_epochs, output.squeeze().detach(), loss.item()\n",
    "    ))\n",
    "    print('W: {} b: {:.2f}'.format(W.detach().numpy(), b.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManualLinearRegressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.W = nn.Parameter(torch.randn(x_train.size(1), requires_grad=True))\n",
    "        self.b = nn.Parameter(torch.randn(1, requires_grad=True))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return (x.matmul(self.W) + self.b).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ManualLinearRegressor()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-5)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 y_pred: tensor([117.8605, 158.7107, 147.2782, 163.2412, 123.1134]) Cost: 871.438293\n",
      "Epoch    1/20 y_pred: tensor([129.2317, 172.3746, 160.7433, 177.9041, 133.5349]) Cost: 289.546570\n",
      "Epoch    2/20 y_pred: tensor([135.5989, 180.0240, 168.2823, 186.1135, 139.3688]) Cost: 107.145340\n",
      "Epoch    3/20 y_pred: tensor([139.1645, 184.3061, 172.5033, 190.7098, 142.6343]) Cost: 49.964241\n",
      "Epoch    4/20 y_pred: tensor([141.1615, 186.7028, 174.8667, 193.2832, 144.4618]) Cost: 32.032772\n",
      "Epoch    5/20 y_pred: tensor([142.2804, 188.0442, 176.1901, 194.7242, 145.4842]) Cost: 26.403889\n",
      "Epoch    6/20 y_pred: tensor([142.9077, 188.7946, 176.9314, 195.5311, 146.0560]) Cost: 24.631245\n",
      "Epoch    7/20 y_pred: tensor([143.2597, 189.2141, 177.3466, 195.9830, 146.3753]) Cost: 24.067318\n",
      "Epoch    8/20 y_pred: tensor([143.4575, 189.4485, 177.5793, 196.2361, 146.5534]) Cost: 23.882330\n",
      "Epoch    9/20 y_pred: tensor([143.5692, 189.5791, 177.7099, 196.3781, 146.6524]) Cost: 23.816011\n",
      "Epoch   10/20 y_pred: tensor([143.6324, 189.6517, 177.7832, 196.4576, 146.7071]) Cost: 23.786936\n",
      "Epoch   11/20 y_pred: tensor([143.6687, 189.6918, 177.8245, 196.5023, 146.7370]) Cost: 23.769609\n",
      "Epoch   12/20 y_pred: tensor([143.6898, 189.7137, 177.8479, 196.5276, 146.7531]) Cost: 23.755856\n",
      "Epoch   13/20 y_pred: tensor([143.7025, 189.7254, 177.8612, 196.5418, 146.7614]) Cost: 23.743305\n",
      "Epoch   14/20 y_pred: tensor([143.7104, 189.7313, 177.8690, 196.5500, 146.7653]) Cost: 23.731043\n",
      "Epoch   15/20 y_pred: tensor([143.7156, 189.7341, 177.8735, 196.5547, 146.7668]) Cost: 23.719006\n",
      "Epoch   16/20 y_pred: tensor([143.7193, 189.7352, 177.8764, 196.5575, 146.7669]) Cost: 23.706964\n",
      "Epoch   17/20 y_pred: tensor([143.7223, 189.7352, 177.8782, 196.5592, 146.7663]) Cost: 23.694925\n",
      "Epoch   18/20 y_pred: tensor([143.7247, 189.7346, 177.8795, 196.5603, 146.7652]) Cost: 23.682814\n",
      "Epoch   19/20 y_pred: tensor([143.7269, 189.7337, 177.8804, 196.5611, 146.7639]) Cost: 23.670900\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "\n",
    "    output = model(x_train)\n",
    "\n",
    "    loss = criterion(output, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    print('Epoch {:4d}/{} y_pred: {} Cost: {:.6f}'.format(\n",
    "        epoch, n_epochs, output.squeeze().detach(), loss.item()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerLinearRegressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(x_train.size(1), 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LayerLinearRegressor()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-5)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 y_pred: tensor([35.9298, 38.7093, 40.5426, 42.4328, 29.9311]) Cost: 18092.789062\n",
      "Epoch    1/20 y_pred: tensor([ 88.4508, 101.8374, 102.7428, 110.1674,  78.0823]) Cost: 5675.182129\n",
      "Epoch    2/20 y_pred: tensor([117.8549, 137.1807, 137.5663, 148.0894, 105.0407]) Cost: 1782.919678\n",
      "Epoch    3/20 y_pred: tensor([134.3168, 156.9684, 157.0626, 169.3205, 120.1341]) Cost: 562.900757\n",
      "Epoch    4/20 y_pred: tensor([143.5328, 168.0471, 167.9777, 181.2069, 128.5847]) Cost: 180.486725\n",
      "Epoch    5/20 y_pred: tensor([148.6921, 174.2500, 174.0886, 187.8616, 133.3162]) Cost: 60.618214\n",
      "Epoch    6/20 y_pred: tensor([151.5802, 177.7230, 177.5097, 191.5872, 135.9656]) Cost: 23.043730\n",
      "Epoch    7/20 y_pred: tensor([153.1967, 179.6677, 179.4249, 193.6730, 137.4493]) Cost: 11.264114\n",
      "Epoch    8/20 y_pred: tensor([154.1014, 180.7567, 180.4970, 194.8406, 138.2803]) Cost: 7.569697\n",
      "Epoch    9/20 y_pred: tensor([154.6074, 181.3667, 181.0972, 195.4943, 138.7459]) Cost: 6.409578\n",
      "Epoch   10/20 y_pred: tensor([154.8903, 181.7085, 181.4330, 195.8602, 139.0069]) Cost: 6.043873\n",
      "Epoch   11/20 y_pred: tensor([155.0483, 181.9002, 181.6209, 196.0649, 139.1534]) Cost: 5.927119\n",
      "Epoch   12/20 y_pred: tensor([155.1363, 182.0078, 181.7260, 196.1795, 139.2358]) Cost: 5.888415\n",
      "Epoch   13/20 y_pred: tensor([155.1852, 182.0683, 181.7847, 196.2435, 139.2823]) Cost: 5.874234\n",
      "Epoch   14/20 y_pred: tensor([155.2122, 182.1024, 181.8174, 196.2793, 139.3087]) Cost: 5.867686\n",
      "Epoch   15/20 y_pred: tensor([155.2269, 182.1218, 181.8356, 196.2992, 139.3238]) Cost: 5.863540\n",
      "Epoch   16/20 y_pred: tensor([155.2347, 182.1329, 181.8457, 196.3103, 139.3327]) Cost: 5.860164\n",
      "Epoch   17/20 y_pred: tensor([155.2386, 182.1395, 181.8512, 196.3164, 139.3380]) Cost: 5.856995\n",
      "Epoch   18/20 y_pred: tensor([155.2404, 182.1434, 181.8542, 196.3198, 139.3413]) Cost: 5.853949\n",
      "Epoch   19/20 y_pred: tensor([155.2411, 182.1459, 181.8557, 196.3216, 139.3435]) Cost: 5.850925\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "\n",
    "    output = model(x_train)\n",
    "\n",
    "    loss = criterion(output, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    print('Epoch {:4d}/{} y_pred: {} Cost: {:.6f}'.format(\n",
    "        epoch, n_epochs, output.squeeze().detach(), loss.item()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerLinearRegressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(x_train.size(1), 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LayerLinearRegressor()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 y_pred: tensor([15.7411, 18.3557, 18.4475, 19.1016, 14.6982]) Cost: 23986.962891\n",
      "Epoch    1/20 y_pred: tensor([76.2238, 91.0521, 90.0762, 97.1034, 70.1474]) Cost: 7519.571289\n",
      "Epoch    2/20 y_pred: tensor([110.0856, 131.7523, 130.1784, 140.7737, 101.1916]) Cost: 2357.917480\n",
      "Epoch    3/20 y_pred: tensor([129.0435, 154.5390, 152.6301, 165.2231, 118.5722]) Cost: 740.012878\n",
      "Epoch    4/20 y_pred: tensor([139.6571, 167.2966, 165.1999, 178.9114, 128.3032]) Cost: 232.885101\n",
      "Epoch    5/20 y_pred: tensor([145.5990, 174.4392, 172.2372, 186.5748, 133.7514]) Cost: 73.927711\n",
      "Epoch    6/20 y_pred: tensor([148.9256, 178.4382, 176.1771, 190.8654, 136.8018]) Cost: 24.101908\n",
      "Epoch    7/20 y_pred: tensor([150.7877, 180.6772, 178.3828, 193.2674, 138.5098]) Cost: 8.484011\n",
      "Epoch    8/20 y_pred: tensor([151.8301, 181.9309, 179.6177, 194.6122, 139.4661]) Cost: 3.588177\n",
      "Epoch    9/20 y_pred: tensor([152.4135, 182.6329, 180.3090, 195.3650, 140.0018]) Cost: 2.053119\n",
      "Epoch   10/20 y_pred: tensor([152.7400, 183.0261, 180.6959, 195.7865, 140.3018]) Cost: 1.571546\n",
      "Epoch   11/20 y_pred: tensor([152.9226, 183.2463, 180.9125, 196.0224, 140.4700]) Cost: 1.420142\n",
      "Epoch   12/20 y_pred: tensor([153.0246, 183.3698, 181.0337, 196.1544, 140.5643]) Cost: 1.372238\n",
      "Epoch   13/20 y_pred: tensor([153.0815, 183.4390, 181.1015, 196.2283, 140.6172]) Cost: 1.356794\n",
      "Epoch   14/20 y_pred: tensor([153.1132, 183.4779, 181.1394, 196.2696, 140.6470]) Cost: 1.351505\n",
      "Epoch   15/20 y_pred: tensor([153.1308, 183.4998, 181.1606, 196.2927, 140.6639]) Cost: 1.349407\n",
      "Epoch   16/20 y_pred: tensor([153.1404, 183.5122, 181.1724, 196.3056, 140.6735]) Cost: 1.348307\n",
      "Epoch   17/20 y_pred: tensor([153.1456, 183.5192, 181.1789, 196.3128, 140.6791]) Cost: 1.347533\n",
      "Epoch   18/20 y_pred: tensor([153.1483, 183.5233, 181.1825, 196.3168, 140.6823]) Cost: 1.346845\n",
      "Epoch   19/20 y_pred: tensor([153.1497, 183.5257, 181.1845, 196.3190, 140.6843]) Cost: 1.346197\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "\n",
    "    output = model(x_train)\n",
    "\n",
    "    loss = F.mse_loss(output, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    print('Epoch {:4d}/{} y_pred: {} Cost: {:.6f}'.format(\n",
    "        epoch, n_epochs, output.squeeze().detach(), loss.item()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(x_train.size(1), 1))\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 y_pred: tensor([51.4497, 58.2111, 59.2689, 64.6877, 43.2571]) Cost: 13550.974609\n",
      "Epoch    1/20 y_pred: tensor([ 96.8978, 112.8382, 113.0929, 123.3008,  84.9242]) Cost: 4252.589844\n",
      "Epoch    2/20 y_pred: tensor([122.3421, 143.4222, 143.2269, 156.1160, 108.2526]) Cost: 1338.037354\n",
      "Epoch    3/20 y_pred: tensor([136.5870, 160.5454, 160.0977, 174.4879, 121.3136]) Cost: 424.476959\n",
      "Epoch    4/20 y_pred: tensor([144.5617, 170.1324, 169.5429, 184.7736, 128.6265]) Cost: 138.121902\n",
      "Epoch    5/20 y_pred: tensor([149.0260, 175.5000, 174.8307, 190.5320, 132.7211]) Cost: 48.362446\n",
      "Epoch    6/20 y_pred: tensor([151.5250, 178.5055, 177.7911, 193.7559, 135.0139]) Cost: 20.225183\n",
      "Epoch    7/20 y_pred: tensor([152.9236, 180.1885, 179.4483, 195.5607, 136.2979]) Cost: 11.402960\n",
      "Epoch    8/20 y_pred: tensor([153.7063, 181.1310, 180.3761, 196.5710, 137.0173]) Cost: 8.635107\n",
      "Epoch    9/20 y_pred: tensor([154.1440, 181.6590, 180.8953, 197.1366, 137.4204]) Cost: 7.764999\n",
      "Epoch   10/20 y_pred: tensor([154.3886, 181.9549, 181.1859, 197.4531, 137.6465]) Cost: 7.489727\n",
      "Epoch   11/20 y_pred: tensor([154.5251, 182.1209, 181.3484, 197.6301, 137.7735]) Cost: 7.400912\n",
      "Epoch   12/20 y_pred: tensor([154.6011, 182.2141, 181.4393, 197.7292, 137.8450]) Cost: 7.370569\n",
      "Epoch   13/20 y_pred: tensor([154.6432, 182.2666, 181.4901, 197.7845, 137.8855]) Cost: 7.358472\n",
      "Epoch   14/20 y_pred: tensor([154.6663, 182.2963, 181.5183, 197.8154, 137.9085]) Cost: 7.352158\n",
      "Epoch   15/20 y_pred: tensor([154.6788, 182.3132, 181.5340, 197.8326, 137.9218]) Cost: 7.347590\n",
      "Epoch   16/20 y_pred: tensor([154.6854, 182.3230, 181.5427, 197.8421, 137.9297]) Cost: 7.343665\n",
      "Epoch   17/20 y_pred: tensor([154.6886, 182.3288, 181.5474, 197.8473, 137.9345]) Cost: 7.339881\n",
      "Epoch   18/20 y_pred: tensor([154.6900, 182.3323, 181.5499, 197.8501, 137.9376]) Cost: 7.336186\n",
      "Epoch   19/20 y_pred: tensor([154.6903, 182.3346, 181.5512, 197.8516, 137.9397]) Cost: 7.332488\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "\n",
    "    output = model(x_train)\n",
    "\n",
    "    loss = F.mse_loss(output, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    print('Epoch {:4d}/{} y_pred: {} Cost: {:.6f}'.format(\n",
    "        epoch, n_epochs, output.squeeze().detach(), loss.item()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab-04-2 Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[73, 80, 75], \n",
    "                             [93, 88, 93], \n",
    "                             [89, 91, 90], \n",
    "                             [96, 98, 100], \n",
    "                             [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x = x_data\n",
    "        self.y = y_data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.x[idx], self.y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CustomDataset(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([73., 80., 75.]), tensor([152.]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=2, shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1f7bd93e8d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[tensor([[73., 80., 75.],\n",
      "        [73., 66., 70.]]), tensor([[152.],\n",
      "        [142.]])]\n",
      "1\n",
      "[tensor([[93., 88., 93.],\n",
      "        [89., 91., 90.]]), tensor([[185.],\n",
      "        [180.]])]\n",
      "2\n",
      "[tensor([[ 96.,  98., 100.]]), tensor([[196.]])]\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, samples in enumerate(train_loader):\n",
    "    print(batch_idx)\n",
    "    print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 Batch: 1/3 Cost: 4.751957\n",
      "Epoch    0/20 Batch: 2/3 Cost: 6.606174\n",
      "Epoch    0/20 Batch: 3/3 Cost: 22.535255\n",
      "Epoch    1/20 Batch: 1/3 Cost: 9.914578\n",
      "Epoch    1/20 Batch: 2/3 Cost: 5.700682\n",
      "Epoch    1/20 Batch: 3/3 Cost: 16.453857\n",
      "Epoch    2/20 Batch: 1/3 Cost: 8.844458\n",
      "Epoch    2/20 Batch: 2/3 Cost: 6.263742\n",
      "Epoch    2/20 Batch: 3/3 Cost: 11.116164\n",
      "Epoch    3/20 Batch: 1/3 Cost: 5.768337\n",
      "Epoch    3/20 Batch: 2/3 Cost: 11.798955\n",
      "Epoch    3/20 Batch: 3/3 Cost: 4.255417\n",
      "Epoch    4/20 Batch: 1/3 Cost: 11.610088\n",
      "Epoch    4/20 Batch: 2/3 Cost: 7.249529\n",
      "Epoch    4/20 Batch: 3/3 Cost: 2.300960\n",
      "Epoch    5/20 Batch: 1/3 Cost: 16.638527\n",
      "Epoch    5/20 Batch: 2/3 Cost: 9.157446\n",
      "Epoch    5/20 Batch: 3/3 Cost: 2.090781\n",
      "Epoch    6/20 Batch: 1/3 Cost: 8.691968\n",
      "Epoch    6/20 Batch: 2/3 Cost: 1.279174\n",
      "Epoch    6/20 Batch: 3/3 Cost: 24.079973\n",
      "Epoch    7/20 Batch: 1/3 Cost: 7.868084\n",
      "Epoch    7/20 Batch: 2/3 Cost: 14.699789\n",
      "Epoch    7/20 Batch: 3/3 Cost: 4.070806\n",
      "Epoch    8/20 Batch: 1/3 Cost: 1.997397\n",
      "Epoch    8/20 Batch: 2/3 Cost: 13.338883\n",
      "Epoch    8/20 Batch: 3/3 Cost: 10.271939\n",
      "Epoch    9/20 Batch: 1/3 Cost: 11.460686\n",
      "Epoch    9/20 Batch: 2/3 Cost: 5.500876\n",
      "Epoch    9/20 Batch: 3/3 Cost: 4.524968\n",
      "Epoch   10/20 Batch: 1/3 Cost: 1.516159\n",
      "Epoch   10/20 Batch: 2/3 Cost: 18.766777\n",
      "Epoch   10/20 Batch: 3/3 Cost: 10.881361\n",
      "Epoch   11/20 Batch: 1/3 Cost: 3.036775\n",
      "Epoch   11/20 Batch: 2/3 Cost: 20.898764\n",
      "Epoch   11/20 Batch: 3/3 Cost: 4.542968\n",
      "Epoch   12/20 Batch: 1/3 Cost: 10.133496\n",
      "Epoch   12/20 Batch: 2/3 Cost: 5.111267\n",
      "Epoch   12/20 Batch: 3/3 Cost: 8.007874\n",
      "Epoch   13/20 Batch: 1/3 Cost: 11.470094\n",
      "Epoch   13/20 Batch: 2/3 Cost: 5.338850\n",
      "Epoch   13/20 Batch: 3/3 Cost: 7.322897\n",
      "Epoch   14/20 Batch: 1/3 Cost: 7.048944\n",
      "Epoch   14/20 Batch: 2/3 Cost: 9.824628\n",
      "Epoch   14/20 Batch: 3/3 Cost: 7.844461\n",
      "Epoch   15/20 Batch: 1/3 Cost: 6.816408\n",
      "Epoch   15/20 Batch: 2/3 Cost: 9.737570\n",
      "Epoch   15/20 Batch: 3/3 Cost: 7.925785\n",
      "Epoch   16/20 Batch: 1/3 Cost: 1.862884\n",
      "Epoch   16/20 Batch: 2/3 Cost: 8.499583\n",
      "Epoch   16/20 Batch: 3/3 Cost: 19.432390\n",
      "Epoch   17/20 Batch: 1/3 Cost: 10.059025\n",
      "Epoch   17/20 Batch: 2/3 Cost: 5.363559\n",
      "Epoch   17/20 Batch: 3/3 Cost: 15.750855\n",
      "Epoch   18/20 Batch: 1/3 Cost: 5.284843\n",
      "Epoch   18/20 Batch: 2/3 Cost: 11.271811\n",
      "Epoch   18/20 Batch: 3/3 Cost: 8.132714\n",
      "Epoch   19/20 Batch: 1/3 Cost: 2.745386\n",
      "Epoch   19/20 Batch: 2/3 Cost: 12.448667\n",
      "Epoch   19/20 Batch: 3/3 Cost: 9.404438\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):\n",
    "    for batch_idx, samples in enumerate(train_loader):\n",
    "        x_train, y_train = samples\n",
    "        \n",
    "        output = model(x_train)\n",
    "        \n",
    "        loss = F.mse_loss(output, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        print('Epoch {:4d}/{} Batch: {}/{} Cost: {:.6f}'.format(\n",
    "            epoch, n_epochs, batch_idx+1, len(train_loader), loss.item()\n",
    "        ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
