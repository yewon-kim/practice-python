{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab-04-1 Multivariate Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[73, 80, 75], \n",
    "                             [93, 88, 93], \n",
    "                             [89, 91, 90], \n",
    "                             [96, 98, 100], \n",
    "                             [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model without torch.nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.6616, -0.1479, -0.3434], requires_grad=True),\n",
       " tensor([0.5755], requires_grad=True))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = torch.randn(x_train.size(1), requires_grad=True)\n",
    "b = torch.randn(1, requires_grad=True)\n",
    "W, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD([W, b], lr=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11.2906, 17.1589, 15.0991, 15.2616, 15.0773], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.matmul(W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 y_pred: tensor([11.2906, 17.1589, 15.0991, 15.2616, 15.0773]) Cost: 24787.566406\n",
      "W: [ 0.9302702   0.12062967 -0.0715034 ] b: 0.58\n",
      "Epoch    1/20 y_pred: tensor([72.7760, 91.0593, 87.9147, 94.5559, 71.4446]) Cost: 7769.993164\n",
      "W: [1.0806886  0.2709602  0.08069359] b: 0.58\n",
      "Epoch    2/20 y_pred: tensor([107.1995, 132.4334, 128.6815, 138.9499, 103.0025]) Cost: 2435.887451\n",
      "W: [1.164889   0.35513872 0.16590251] b: 0.58\n",
      "Epoch    3/20 y_pred: tensor([126.4720, 155.5972, 151.5053, 163.8045, 120.6706]) Cost: 763.928772\n",
      "W: [1.2120163  0.40228114 0.21360727] b: 0.58\n",
      "Epoch    4/20 y_pred: tensor([137.2621, 168.5656, 164.2836, 177.7197, 130.5621]) Cost: 239.858368\n",
      "W: [1.238388   0.42868838 0.24031483] b: 0.58\n",
      "Epoch    5/20 y_pred: tensor([143.3032, 175.8261, 171.4377, 185.5104, 136.1000]) Cost: 75.589951\n",
      "W: [1.2531391  0.44348678 0.25526685] b: 0.58\n",
      "Epoch    6/20 y_pred: tensor([146.6855, 179.8910, 175.4431, 189.8721, 139.2003]) Cost: 24.100239\n",
      "W: [1.2613844  0.45178577 0.26363733] b: 0.58\n",
      "Epoch    7/20 y_pred: tensor([148.5792, 182.1666, 177.6855, 192.3141, 140.9360]) Cost: 7.960946\n",
      "W: [1.2659873  0.45644602 0.2683231 ] b: 0.58\n",
      "Epoch    8/20 y_pred: tensor([149.6395, 183.4406, 178.9411, 193.6813, 141.9076]) Cost: 2.901948\n",
      "W: [1.268551   0.45906904 0.27094588] b: 0.58\n",
      "Epoch    9/20 y_pred: tensor([150.2332, 184.1538, 179.6440, 194.4468, 142.4516]) Cost: 1.316099\n",
      "W: [1.2699729  0.46055147 0.27241367] b: 0.58\n",
      "Epoch   10/20 y_pred: tensor([150.5657, 184.5531, 180.0376, 194.8754, 142.7559]) Cost: 0.818899\n",
      "W: [1.2707558  0.46139538 0.27323487] b: 0.58\n",
      "Epoch   11/20 y_pred: tensor([150.7520, 184.7765, 180.2579, 195.1154, 142.9263]) Cost: 0.662929\n",
      "W: [1.2711807  0.4618818  0.27369407] b: 0.58\n",
      "Epoch   12/20 y_pred: tensor([150.8564, 184.9015, 180.3814, 195.2498, 143.0216]) Cost: 0.613895\n",
      "W: [1.2714053  0.462168   0.27395055] b: 0.58\n",
      "Epoch   13/20 y_pred: tensor([150.9149, 184.9715, 180.4505, 195.3250, 143.0748]) Cost: 0.598394\n",
      "W: [1.2715178  0.46234214 0.27409357] b: 0.58\n",
      "Epoch   14/20 y_pred: tensor([150.9478, 185.0105, 180.4892, 195.3672, 143.1045]) Cost: 0.593410\n",
      "W: [1.2715675  0.46245354 0.27417305] b: 0.58\n",
      "Epoch   15/20 y_pred: tensor([150.9663, 185.0324, 180.5109, 195.3908, 143.1210]) Cost: 0.591714\n",
      "W: [1.271582   0.4625298  0.27421698] b: 0.58\n",
      "Epoch   16/20 y_pred: tensor([150.9767, 185.0445, 180.5231, 195.4041, 143.1302]) Cost: 0.591058\n",
      "W: [1.2715769 0.4625864 0.274241 ] b: 0.58\n",
      "Epoch   17/20 y_pred: tensor([150.9827, 185.0513, 180.5300, 195.4115, 143.1353]) Cost: 0.590713\n",
      "W: [1.2715607  0.46263197 0.27425385] b: 0.58\n",
      "Epoch   18/20 y_pred: tensor([150.9861, 185.0549, 180.5338, 195.4157, 143.1380]) Cost: 0.590468\n",
      "W: [1.2715383  0.46267137 0.27426046] b: 0.58\n",
      "Epoch   19/20 y_pred: tensor([150.9881, 185.0569, 180.5360, 195.4181, 143.1394]) Cost: 0.590275\n",
      "W: [1.2715125 0.4627073 0.2742636] b: 0.58\n",
      "Epoch   20/20 y_pred: tensor([150.9893, 185.0580, 180.5373, 195.4195, 143.1401]) Cost: 0.590072\n",
      "W: [1.2714847  0.46274132 0.27426475] b: 0.58\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "for epoch in range(n_epochs + 1):\n",
    "    \n",
    "    output = (x_train.matmul(W) + b).unsqueeze(1)\n",
    "    \n",
    "    loss = torch.mean((output - y_train)**2)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    print('Epoch {:4d}/{} y_pred: {} Cost: {:.6f}'.format(\n",
    "        epoch, n_epochs, output.squeeze().detach(), loss.item()\n",
    "    ))\n",
    "    print('W: {} b: {:.2f}'.format(W.detach().numpy(), b.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManualLinearRegressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.W = nn.Parameter(torch.randn(x_train.size(1), requires_grad=True))\n",
    "        self.b = nn.Parameter(torch.randn(1, requires_grad=True))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return (x.matmul(self.W) + self.b).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ManualLinearRegressor()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-5)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 y_pred: tensor([110.0358, 115.1027, 122.5886, 132.4487,  83.8398]) Cost: 3472.813232\n",
      "Epoch    1/20 y_pred: tensor([132.8509, 142.5303, 149.6106, 161.8753, 104.7613]) Cost: 1129.018311\n",
      "Epoch    2/20 y_pred: tensor([145.6229, 157.8870, 164.7388, 178.3498, 116.4757]) Cost: 394.340820\n",
      "Epoch    3/20 y_pred: tensor([152.7722, 166.4855, 173.2082, 187.5730, 123.0353]) Cost: 164.037415\n",
      "Epoch    4/20 y_pred: tensor([156.7735, 171.3004, 177.9494, 192.7365, 126.7090]) Cost: 91.827576\n",
      "Epoch    5/20 y_pred: tensor([159.0124, 173.9969, 180.6035, 195.6270, 128.7669]) Cost: 69.171944\n",
      "Epoch    6/20 y_pred: tensor([160.2646, 175.5075, 182.0891, 197.2450, 129.9203]) Cost: 62.048866\n",
      "Epoch    7/20 y_pred: tensor([160.9643, 176.3541, 182.9203, 198.1505, 130.5672]) Cost: 59.794605\n",
      "Epoch    8/20 y_pred: tensor([161.3548, 176.8290, 183.3853, 198.6572, 130.9305]) Cost: 59.066334\n",
      "Epoch    9/20 y_pred: tensor([161.5721, 177.0958, 183.6453, 198.9406, 131.1352]) Cost: 58.816387\n",
      "Epoch   10/20 y_pred: tensor([161.6925, 177.2460, 183.7905, 199.0990, 131.2509]) Cost: 58.716480\n",
      "Epoch   11/20 y_pred: tensor([161.7586, 177.3311, 183.8713, 199.1873, 131.3169]) Cost: 58.663483\n",
      "Epoch   12/20 y_pred: tensor([161.7943, 177.3795, 183.9162, 199.2365, 131.3550]) Cost: 58.625347\n",
      "Epoch   13/20 y_pred: tensor([161.8129, 177.4076, 183.9409, 199.2637, 131.3775]) Cost: 58.591747\n",
      "Epoch   14/20 y_pred: tensor([161.8221, 177.4241, 183.9543, 199.2786, 131.3913]) Cost: 58.559654\n",
      "Epoch   15/20 y_pred: tensor([161.8259, 177.4343, 183.9614, 199.2867, 131.4002]) Cost: 58.527943\n",
      "Epoch   16/20 y_pred: tensor([161.8268, 177.4409, 183.9651, 199.2909, 131.4064]) Cost: 58.496437\n",
      "Epoch   17/20 y_pred: tensor([161.8259, 177.4455, 183.9667, 199.2930, 131.4110]) Cost: 58.464989\n",
      "Epoch   18/20 y_pred: tensor([161.8242, 177.4490, 183.9672, 199.2938, 131.4148]) Cost: 58.433533\n",
      "Epoch   19/20 y_pred: tensor([161.8219, 177.4518, 183.9671, 199.2940, 131.4181]) Cost: 58.402233\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "\n",
    "    output = model(x_train)\n",
    "\n",
    "    loss = criterion(output, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    print('Epoch {:4d}/{} y_pred: {} Cost: {:.6f}'.format(\n",
    "        epoch, n_epochs, output.squeeze().detach(), loss.item()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerLinearRegressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(x_train.size(1), 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LayerLinearRegressor()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-5)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 y_pred: tensor([10.4816,  5.9370,  9.3333,  9.6368,  3.2908]) Cost: 27037.925781\n",
      "Epoch    1/20 y_pred: tensor([74.6810, 83.1025, 85.3645, 92.4330, 62.1493]) Cost: 8483.892578\n",
      "Epoch    2/20 y_pred: tensor([110.6233, 126.3051, 127.9314, 138.7874,  95.1025]) Cost: 2668.183105\n",
      "Epoch    3/20 y_pred: tensor([130.7455, 150.4931, 151.7628, 164.7394, 113.5523]) Cost: 845.262878\n",
      "Epoch    4/20 y_pred: tensor([142.0106, 164.0354, 165.1050, 179.2688, 123.8823]) Cost: 273.869476\n",
      "Epoch    5/20 y_pred: tensor([148.3168, 171.6177, 172.5746, 187.4032, 129.6662]) Cost: 94.763107\n",
      "Epoch    6/20 y_pred: tensor([151.8469, 175.8632, 176.7563, 191.9572, 132.9050]) Cost: 38.618080\n",
      "Epoch    7/20 y_pred: tensor([153.8227, 178.2405, 179.0974, 194.5066, 134.7188]) Cost: 21.014811\n",
      "Epoch    8/20 y_pred: tensor([154.9282, 179.5719, 180.4079, 195.9338, 135.7348]) Cost: 15.492414\n",
      "Epoch    9/20 y_pred: tensor([155.5465, 180.3177, 181.1414, 196.7327, 136.3042]) Cost: 13.756691\n",
      "Epoch   10/20 y_pred: tensor([155.8921, 180.7356, 181.5518, 197.1799, 136.6236]) Cost: 13.207972\n",
      "Epoch   11/20 y_pred: tensor([156.0850, 180.9700, 181.7815, 197.4301, 136.8029]) Cost: 13.031215\n",
      "Epoch   12/20 y_pred: tensor([156.1924, 181.1017, 181.9098, 197.5700, 136.9039]) Cost: 12.971098\n",
      "Epoch   13/20 y_pred: tensor([156.2519, 181.1758, 181.9815, 197.6482, 136.9609]) Cost: 12.947566\n",
      "Epoch   14/20 y_pred: tensor([156.2846, 181.2178, 182.0215, 197.6918, 136.9934]) Cost: 12.935466\n",
      "Epoch   15/20 y_pred: tensor([156.3023, 181.2417, 182.0437, 197.7161, 137.0122]) Cost: 12.926931\n",
      "Epoch   16/20 y_pred: tensor([156.3116, 181.2554, 182.0559, 197.7296, 137.0232]) Cost: 12.919604\n",
      "Epoch   17/20 y_pred: tensor([156.3162, 181.2635, 182.0626, 197.7370, 137.0300]) Cost: 12.912623\n",
      "Epoch   18/20 y_pred: tensor([156.3182, 181.2685, 182.0661, 197.7410, 137.0343]) Cost: 12.905678\n",
      "Epoch   19/20 y_pred: tensor([156.3187, 181.2717, 182.0679, 197.7431, 137.0373]) Cost: 12.898821\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "\n",
    "    output = model(x_train)\n",
    "\n",
    "    loss = criterion(output, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    print('Epoch {:4d}/{} y_pred: {} Cost: {:.6f}'.format(\n",
    "        epoch, n_epochs, output.squeeze().detach(), loss.item()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerLinearRegressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(x_train.size(1), 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LayerLinearRegressor()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 y_pred: tensor([-50.1875, -55.0341, -56.9127, -62.6403, -40.0790]) Cost: 50934.269531\n",
      "Epoch    1/20 y_pred: tensor([37.9498, 50.8997, 47.4660, 51.0255, 40.7216]) Cost: 15966.099609\n",
      "Epoch    2/20 y_pred: tensor([ 87.2949, 110.2080, 105.9039, 114.6629,  85.9587]) Cost: 5005.436523\n",
      "Epoch    3/20 y_pred: tensor([114.9215, 143.4124, 138.6212, 150.2911, 111.2852]) Cost: 1569.849854\n",
      "Epoch    4/20 y_pred: tensor([130.3889, 162.0022, 156.9384, 170.2381, 125.4643]) Cost: 492.975159\n",
      "Epoch    5/20 y_pred: tensor([139.0487, 172.4098, 167.1937, 181.4058, 133.4026]) Cost: 155.431839\n",
      "Epoch    6/20 y_pred: tensor([143.8972, 178.2365, 172.9352, 187.6582, 137.8467]) Cost: 49.629513\n",
      "Epoch    7/20 y_pred: tensor([146.6118, 181.4986, 176.1498, 191.1587, 140.3347]) Cost: 16.465590\n",
      "Epoch    8/20 y_pred: tensor([148.1319, 183.3248, 177.9496, 193.1185, 141.7274]) Cost: 6.070072\n",
      "Epoch    9/20 y_pred: tensor([148.9830, 184.3470, 178.9572, 194.2158, 142.5070]) Cost: 2.811227\n",
      "Epoch   10/20 y_pred: tensor([149.4598, 184.9193, 179.5215, 194.8302, 142.9433]) Cost: 1.789311\n",
      "Epoch   11/20 y_pred: tensor([149.7269, 185.2395, 179.8374, 195.1742, 143.1874]) Cost: 1.468560\n",
      "Epoch   12/20 y_pred: tensor([149.8766, 185.4186, 180.0143, 195.3669, 143.3239]) Cost: 1.367605\n",
      "Epoch   13/20 y_pred: tensor([149.9606, 185.5188, 180.1135, 195.4748, 143.4002]) Cost: 1.335515\n",
      "Epoch   14/20 y_pred: tensor([150.0078, 185.5748, 180.1690, 195.5352, 143.4427]) Cost: 1.325050\n",
      "Epoch   15/20 y_pred: tensor([150.0344, 185.6060, 180.2001, 195.5691, 143.4663]) Cost: 1.321323\n",
      "Epoch   16/20 y_pred: tensor([150.0495, 185.6233, 180.2177, 195.5881, 143.4794]) Cost: 1.319729\n",
      "Epoch   17/20 y_pred: tensor([150.0581, 185.6329, 180.2275, 195.5988, 143.4865]) Cost: 1.318804\n",
      "Epoch   18/20 y_pred: tensor([150.0631, 185.6381, 180.2331, 195.6048, 143.4904]) Cost: 1.318084\n",
      "Epoch   19/20 y_pred: tensor([150.0661, 185.6409, 180.2363, 195.6082, 143.4924]) Cost: 1.317428\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "\n",
    "    output = model(x_train)\n",
    "\n",
    "    loss = F.mse_loss(output, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    print('Epoch {:4d}/{} y_pred: {} Cost: {:.6f}'.format(\n",
    "        epoch, n_epochs, output.squeeze().detach(), loss.item()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(x_train.size(1), 1))\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 y_pred: tensor([-114.0371, -137.9123, -135.4440, -147.6318, -105.2794]) Cost: 90756.585938\n",
      "Epoch    1/20 y_pred: tensor([3.6124, 3.4946, 3.8862, 4.0953, 2.5787]) Cost: 28448.974609\n",
      "Epoch    2/20 y_pred: tensor([69.4798, 82.6634, 81.8919, 89.0417, 62.9647]) Cost: 8918.843750\n",
      "Epoch    3/20 y_pred: tensor([106.3563, 126.9872, 125.5644, 136.6000,  96.7729]) Cost: 2797.183105\n",
      "Epoch    4/20 y_pred: tensor([127.0019, 151.8027, 150.0150, 163.2261, 115.7010]) Cost: 878.367554\n",
      "Epoch    5/20 y_pred: tensor([138.5603, 165.6961, 163.7039, 178.1330, 126.2984]) Cost: 276.919922\n",
      "Epoch    6/20 y_pred: tensor([145.0312, 173.4747, 171.3677, 186.4787, 132.2318]) Cost: 88.397293\n",
      "Epoch    7/20 y_pred: tensor([148.6538, 177.8298, 175.6584, 191.1512, 135.5538]) Cost: 29.304590\n",
      "Epoch    8/20 y_pred: tensor([150.6817, 180.2682, 178.0604, 193.7670, 137.4139]) Cost: 10.781565\n",
      "Epoch    9/20 y_pred: tensor([151.8168, 181.6336, 179.4052, 195.2315, 138.4556]) Cost: 4.974728\n",
      "Epoch   10/20 y_pred: tensor([152.4521, 182.3981, 180.1580, 196.0513, 139.0390]) Cost: 3.153813\n",
      "Epoch   11/20 y_pred: tensor([152.8075, 182.8264, 180.5794, 196.5103, 139.3658]) Cost: 2.582342\n",
      "Epoch   12/20 y_pred: tensor([153.0063, 183.0663, 180.8153, 196.7672, 139.5491]) Cost: 2.402421\n",
      "Epoch   13/20 y_pred: tensor([153.1173, 183.2008, 180.9473, 196.9109, 139.6519]) Cost: 2.345285\n",
      "Epoch   14/20 y_pred: tensor([153.1792, 183.2762, 181.0211, 196.9913, 139.7096]) Cost: 2.326609\n",
      "Epoch   15/20 y_pred: tensor([153.2137, 183.3186, 181.0623, 197.0363, 139.7422]) Cost: 2.319995\n",
      "Epoch   16/20 y_pred: tensor([153.2327, 183.3425, 181.0854, 197.0614, 139.7607]) Cost: 2.317191\n",
      "Epoch   17/20 y_pred: tensor([153.2431, 183.3561, 181.0982, 197.0754, 139.7712]) Cost: 2.315532\n",
      "Epoch   18/20 y_pred: tensor([153.2487, 183.3638, 181.1053, 197.0832, 139.7774]) Cost: 2.314249\n",
      "Epoch   19/20 y_pred: tensor([153.2516, 183.3683, 181.1092, 197.0875, 139.7810]) Cost: 2.313102\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "\n",
    "    output = model(x_train)\n",
    "\n",
    "    loss = F.mse_loss(output, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    print('Epoch {:4d}/{} y_pred: {} Cost: {:.6f}'.format(\n",
    "        epoch, n_epochs, output.squeeze().detach(), loss.item()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab-04-2 Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[73, 80, 75], \n",
    "                             [93, 88, 93], \n",
    "                             [89, 91, 90], \n",
    "                             [96, 98, 100], \n",
    "                             [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x = x_data\n",
    "        self.y = y_data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.x[idx], self.y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CustomDataset(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([73., 80., 75.]), tensor([152.]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=2, shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x2097f3d53c8>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[tensor([[73., 80., 75.],\n",
      "        [73., 66., 70.]]), tensor([[152.],\n",
      "        [142.]])]\n",
      "1\n",
      "[tensor([[ 89.,  91.,  90.],\n",
      "        [ 96.,  98., 100.]]), tensor([[180.],\n",
      "        [196.]])]\n",
      "2\n",
      "[tensor([[93., 88., 93.]]), tensor([[185.]])]\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, samples in enumerate(train_loader):\n",
    "    print(batch_idx)\n",
    "    print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 Batch: 1/3 Cost: 0.388091\n",
      "Epoch    0/20 Batch: 2/3 Cost: 2.831610\n",
      "Epoch    0/20 Batch: 3/3 Cost: 5.461881\n",
      "Epoch    1/20 Batch: 1/3 Cost: 2.779845\n",
      "Epoch    1/20 Batch: 2/3 Cost: 1.845090\n",
      "Epoch    1/20 Batch: 3/3 Cost: 2.045185\n",
      "Epoch    2/20 Batch: 1/3 Cost: 0.652663\n",
      "Epoch    2/20 Batch: 2/3 Cost: 2.653633\n",
      "Epoch    2/20 Batch: 3/3 Cost: 5.279631\n",
      "Epoch    3/20 Batch: 1/3 Cost: 2.732191\n",
      "Epoch    3/20 Batch: 2/3 Cost: 1.912549\n",
      "Epoch    3/20 Batch: 3/3 Cost: 2.114500\n",
      "Epoch    4/20 Batch: 1/3 Cost: 4.595750\n",
      "Epoch    4/20 Batch: 2/3 Cost: 2.770309\n",
      "Epoch    4/20 Batch: 3/3 Cost: 0.765945\n",
      "Epoch    5/20 Batch: 1/3 Cost: 2.498620\n",
      "Epoch    5/20 Batch: 2/3 Cost: 3.041684\n",
      "Epoch    5/20 Batch: 3/3 Cost: 1.195188\n",
      "Epoch    6/20 Batch: 1/3 Cost: 3.358598\n",
      "Epoch    6/20 Batch: 2/3 Cost: 2.010214\n",
      "Epoch    6/20 Batch: 3/3 Cost: 1.204045\n",
      "Epoch    7/20 Batch: 1/3 Cost: 3.441093\n",
      "Epoch    7/20 Batch: 2/3 Cost: 1.929599\n",
      "Epoch    7/20 Batch: 3/3 Cost: 1.158934\n",
      "Epoch    8/20 Batch: 1/3 Cost: 3.359736\n",
      "Epoch    8/20 Batch: 2/3 Cost: 1.893952\n",
      "Epoch    8/20 Batch: 3/3 Cost: 1.305903\n",
      "Epoch    9/20 Batch: 1/3 Cost: 2.312961\n",
      "Epoch    9/20 Batch: 2/3 Cost: 2.875283\n",
      "Epoch    9/20 Batch: 3/3 Cost: 1.274464\n",
      "Epoch   10/20 Batch: 1/3 Cost: 0.347981\n",
      "Epoch   10/20 Batch: 2/3 Cost: 3.754465\n",
      "Epoch   10/20 Batch: 3/3 Cost: 3.637164\n",
      "Epoch   11/20 Batch: 1/3 Cost: 1.893871\n",
      "Epoch   11/20 Batch: 2/3 Cost: 2.091995\n",
      "Epoch   11/20 Batch: 3/3 Cost: 5.376064\n",
      "Epoch   12/20 Batch: 1/3 Cost: 2.851950\n",
      "Epoch   12/20 Batch: 2/3 Cost: 2.053617\n",
      "Epoch   12/20 Batch: 3/3 Cost: 4.427154\n",
      "Epoch   13/20 Batch: 1/3 Cost: 2.011766\n",
      "Epoch   13/20 Batch: 2/3 Cost: 2.548774\n",
      "Epoch   13/20 Batch: 3/3 Cost: 5.198742\n",
      "Epoch   14/20 Batch: 1/3 Cost: 1.924753\n",
      "Epoch   14/20 Batch: 2/3 Cost: 2.129470\n",
      "Epoch   14/20 Batch: 3/3 Cost: 5.307365\n",
      "Epoch   15/20 Batch: 1/3 Cost: 2.733551\n",
      "Epoch   15/20 Batch: 2/3 Cost: 1.818139\n",
      "Epoch   15/20 Batch: 3/3 Cost: 1.973721\n",
      "Epoch   16/20 Batch: 1/3 Cost: 4.211125\n",
      "Epoch   16/20 Batch: 2/3 Cost: 2.806381\n",
      "Epoch   16/20 Batch: 3/3 Cost: 0.846958\n",
      "Epoch   17/20 Batch: 1/3 Cost: 3.375199\n",
      "Epoch   17/20 Batch: 2/3 Cost: 2.002254\n",
      "Epoch   17/20 Batch: 3/3 Cost: 1.181051\n",
      "Epoch   18/20 Batch: 1/3 Cost: 0.392515\n",
      "Epoch   18/20 Batch: 2/3 Cost: 2.755221\n",
      "Epoch   18/20 Batch: 3/3 Cost: 5.279420\n",
      "Epoch   19/20 Batch: 1/3 Cost: 2.716196\n",
      "Epoch   19/20 Batch: 2/3 Cost: 3.826468\n",
      "Epoch   19/20 Batch: 3/3 Cost: 3.256622\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):\n",
    "    for batch_idx, samples in enumerate(train_loader):\n",
    "        x_train, y_train = samples\n",
    "        \n",
    "        output = model(x_train)\n",
    "        \n",
    "        loss = F.mse_loss(output, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        print('Epoch {:4d}/{} Batch: {}/{} Cost: {:.6f}'.format(\n",
    "            epoch, n_epochs, batch_idx+1, len(train_loader), loss.item()\n",
    "        ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
